import { GoogleGenAI, Type, Modality, setDefaultBaseUrls } from "@google/genai";
import { 
  NovelConfig, WorldStructure, AppSettings, Faction, MapRegion, Character, Chapter, 
  WikiEntry, VideoScene, VectorRecord, Volume, PlotLoop 
} from '../types';
import { db } from './db';
import { tokenCounter } from './tokenCounter';
import { retrieveRelevantChapters, retrieveRelevantCharacters } from './ragService';
import { 
  findPreviousChapter, 
  extractLastContent, 
  getChapterAncestors as getVolumeChapterAncestors,
  getVolumeProgress 
} from './volumeService';
import { buildLoopContextForPrompt } from './plotLoopService';

// --- Shared Utilities ---

export const stripHtml = (html: string) => {
   if (typeof document === 'undefined') return html; 
   const tmp = document.createElement("DIV");
   tmp.innerHTML = html;
   return tmp.textContent || tmp.innerText || "";
}

const getGoogleAI = (settings: AppSettings) => {
    // Falls back to empty string if not provided; error handling is done in caller
    const options: any = { apiKey: settings.apiKey || '' };
    if (settings.baseUrl) {
        // Set the default base URL for the Google GenAI client
        setDefaultBaseUrls({geminiUrl: settings.baseUrl});
    }
    console.log('GoogleGenAI options:', options);
    return new GoogleGenAI(options);
};

export interface OpenAIMessage { role: string; content: string; }

// Basic OpenAI Fetch Wrapper for DeepSeek / Custom / OpenAI
const callOpenAI = async (baseUrl: string, apiKey: string, model: string, messages: OpenAIMessage[], jsonMode = false) => {
    const url = `${baseUrl.replace(/\/$/, '')}/chat/completions`;
    const headers: any = {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
    };
    
    const body: any = {
        model,
        messages,
        temperature: 0.7,
    };
    
    if (jsonMode) {
        body.response_format = { type: 'json_object' };
    }

    const res = await fetch(url, {
        method: 'POST',
        headers,
        body: JSON.stringify(body)
    });

    if (!res.ok) {
        const err = await res.text();
        throw new Error(`OpenAI/DeepSeek API Error: ${err}`);
    }

    const data = await res.json();
    return data.choices[0].message.content;
}

const ensureString = (val: any) => typeof val === 'string' ? val : '';

export const buildNovelContext = (config: NovelConfig) => {
  return `
    å°è¯´æ ‡é¢˜: ${config.title}
    ç±»å‹: ${config.genre}
    ä¸–ç•Œè®¾å®š: ${config.worldSetting}
    ä¸»è§’ç±»å‹: ${config.protagonistArchetype}
    é‡‘æ‰‹æŒ‡/ç‰¹æ®Šèƒ½åŠ›: ${config.goldenFinger}
    ä¸»çº¿å‰§æƒ…: ${config.mainPlot}
    å™äº‹åŸºè°ƒ: ${config.narrativeTone}
    æ ‡ç­¾: ${config.tags.join(', ')}
    
    æ³¨æ„:
    - ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸Šè®¾å®šè¿›è¡Œåˆ›ä½œ
    - ä¿æŒå™äº‹é£æ ¼çš„ä¸€è‡´æ€§
    - åœ¨ç”Ÿæˆæ–°å†…å®¹æ—¶è¦è€ƒè™‘åˆ°æ ‡ç­¾æ‰€ä»£è¡¨çš„å…ƒç´ 
  `;
};

export const getChapterAncestors = (chapterId: string, allChapters: Chapter[]): Chapter[] => {
    const ancestors: Chapter[] = [];
    let current = allChapters.find(c => c.id === chapterId);
    while (current && current.parentId) {
        const parent = allChapters.find(c => c.id === current?.parentId);
        if (parent) {
            ancestors.unshift(parent);
            current = parent;
        } else {
            break;
        }
    }
    return ancestors;
};

// --- Generators ---

export const generateProjectIdea = async (input: string, settings: AppSettings): Promise<Partial<NovelConfig>> => {
    const prompt = input 
        ? `åŸºäºåˆ›æ„ "${input}"ï¼Œå®Œå–„ä¸€éƒ¨ç½‘æ–‡å°è¯´çš„è®¾å®šã€‚`
        : `éšæœºæ„æ€ä¸€éƒ¨å½“å‰çƒ­é—¨é¢˜æçš„ç½‘æ–‡å°è¯´è®¾å®šã€‚`;
        
    const systemPrompt = `è¯·è¿”å› JSON æ ¼å¼ï¼ŒåŒ…å«: title, genre, worldSetting, protagonistArchetype, goldenFinger, mainPlot (100å­—å·¦å³), pacing, narrativeTone, tags (æ•°ç»„).`;

    if (settings.provider === 'google') {
        const ai = getGoogleAI(settings);
        const response = await ai.models.generateContent({
            model: settings.model,
            contents: `${systemPrompt}\n${prompt}`,
            config: {
                responseMimeType: 'application/json',
                responseSchema: {
                    type: Type.OBJECT,
                    properties: {
                        title: { type: Type.STRING },
                        genre: { type: Type.STRING },
                        worldSetting: { type: Type.STRING },
                        protagonistArchetype: { type: Type.STRING },
                        goldenFinger: { type: Type.STRING },
                        mainPlot: { type: Type.STRING },
                        pacing: { type: Type.STRING },
                        narrativeTone: { type: Type.STRING },
                        tags: { type: Type.ARRAY, items: { type: Type.STRING } }
                    }
                }
            }
        });
        return JSON.parse(response.text || "{}");
    } else {
        const res = await callOpenAI(
            settings.baseUrl || '', 
            settings.apiKey, 
            settings.model, 
            [{ role: 'system', content: systemPrompt }, { role: 'user', content: prompt }],
            true
        );
        return JSON.parse(res);
    }
};

export const generateWorldStructure = async (config: NovelConfig, settings: AppSettings): Promise<WorldStructure> => {
    const context = buildNovelContext(config);
    const prompt = `åŸºäºä»¥ä¸‹å°è¯´è®¾å®šï¼Œæ„å»ºè¯¦ç»†çš„ä¸–ç•Œè§‚ã€‚è¿”å› JSON åŒ…å«: worldView (è¯¦ç»†ä¸–ç•Œè§‚è®¾å®š), centralConflict (æ ¸å¿ƒçŸ›ç›¾), keyPlotPoints (3-5ä¸ªå…³é”®å‰§æƒ…èŠ‚ç‚¹æ•°ç»„).`;
    
    if (settings.provider === 'google') {
         const ai = getGoogleAI(settings);
         const response = await ai.models.generateContent({
             model: settings.model,
             contents: `${context}\n${prompt}`,
             config: {
                 responseMimeType: 'application/json',
                 responseSchema: {
                     type: Type.OBJECT,
                     properties: {
                         worldView: { type: Type.STRING },
                         centralConflict: { type: Type.STRING },
                         keyPlotPoints: { type: Type.ARRAY, items: { type: Type.STRING } }
                     }
                 }
             }
         });
         return JSON.parse(response.text || "{}");
    } else {
         const res = await callOpenAI(
            settings.baseUrl || '', 
            settings.apiKey, 
            settings.model, 
            [{ role: 'system', content: "Output JSON." }, { role: 'user', content: `${context}\n${prompt}` }],
            true
         );
         
         // å¤„ç†OpenAIæ ¼å¼çš„å“åº”
         let parsedResponse;
         if (typeof res === 'string') {
             // å¦‚æœæ˜¯æ™®é€šå­—ç¬¦ä¸²ï¼Œç›´æ¥è§£æ
             parsedResponse = JSON.parse(res);
         } else {
             // å¦‚æœæ˜¯å®Œæ•´çš„OpenAIå“åº”å¯¹è±¡ï¼ˆåŒ…å«choicesç­‰å­—æ®µï¼‰
             const responseObject = res as any;
             if (responseObject.choices && responseObject.choices[0] && responseObject.choices[0].message) {
                 // æå–contentå­—æ®µå¹¶è§£æ
                 const content = responseObject.choices[0].message.content;
                 parsedResponse = JSON.parse(content);
             } else {
                 // å…¶ä»–æƒ…å†µç›´æ¥è§£æ
                 parsedResponse = JSON.parse(JSON.stringify(res));
             }
         }

         // ç¡®ä¿è¿”å›çš„æ•°æ®ç»“æ„ç¬¦åˆWorldStructureæ¥å£
         const worldStructure: WorldStructure = {
             worldView: '',
             centralConflict: '',
             keyPlotPoints: [],
             factions: [],
             wikiEntries: []
         };

         // å¤„ç†worldViewå­—æ®µ
         if (typeof parsedResponse.worldView === 'string') {
             worldStructure.worldView = parsedResponse.worldView;
         } else if (typeof parsedResponse.worldView === 'object') {
             // å¦‚æœworldViewæ˜¯å¯¹è±¡ï¼Œå°†å…¶è½¬æ¢ä¸ºæ˜“è¯»çš„æ ¼å¼
             const worldViewObj = parsedResponse.worldView;
             let formattedWorldView = '';
             
             // éå†å¯¹è±¡çš„æ‰€æœ‰é”®å€¼å¯¹ï¼Œå°†å…¶è½¬æ¢ä¸ºæ˜“è¯»çš„æ–‡æœ¬æ ¼å¼
             for (const [key, value] of Object.entries(worldViewObj)) {
                 formattedWorldView += `## ${key}\n\n`;
                 
                 if (typeof value === 'string') {
                     formattedWorldView += `${value}\n\n`;
                 } else if (typeof value === 'object') {
                     // å¦‚æœå€¼æ˜¯å¯¹è±¡ï¼Œè¿›ä¸€æ­¥å¤„ç†å…¶å†…å®¹
                     for (const [subKey, subValue] of Object.entries(value)) {
                         formattedWorldView += `### ${subKey}\n\n`;
                         
                         if (typeof subValue === 'string') {
                             formattedWorldView += `${subValue}\n\n`;
                         } else if (Array.isArray(subValue)) {
                             // å¦‚æœæ˜¯æ•°ç»„ï¼Œé€é¡¹åˆ—å‡º
                             subValue.forEach((item: any) => {
                                 if (typeof item === 'string') {
                                     formattedWorldView += `- ${item}\n`;
                                 } else if (typeof item === 'object') {
                                     formattedWorldView += `- ${JSON.stringify(item, null, 2)}\n`;
                                 } else {
                                     formattedWorldView += `- ${String(item)}\n`;
                                 }
                             });
                             formattedWorldView += '\n';
                         } else if (typeof subValue === 'object') {
                             // å¦‚æœæ˜¯å¯¹è±¡ï¼Œè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
                             formattedWorldView += `${JSON.stringify(subValue, null, 2)}\n\n`;
                         } else {
                             formattedWorldView += `${String(subValue)}\n\n`;
                         }
                     }
                 }
                 formattedWorldView += '\n';
             }
             
             worldStructure.worldView = formattedWorldView.trim();
         }

         // å¤„ç†centralConflictå­—æ®µ
         if (typeof parsedResponse.centralConflict === 'string') {
             worldStructure.centralConflict = parsedResponse.centralConflict;
         } else if (typeof parsedResponse.centralConflict === 'object') {
             // å¦‚æœcentralConflictæ˜¯å¯¹è±¡ï¼Œå°†å…¶è½¬æ¢ä¸ºæ˜“è¯»çš„æ ¼å¼
             const conflictObj = parsedResponse.centralConflict;
             let formattedConflict = '';
             
             // éå†å¯¹è±¡çš„æ‰€æœ‰é”®å€¼å¯¹
             for (const [key, value] of Object.entries(conflictObj)) {
                 formattedConflict += `## ${key}\n\n`;
                 
                 if (typeof value === 'string') {
                     formattedConflict += `${value}\n\n`;
                 } else if (Array.isArray(value)) {
                     // å¦‚æœæ˜¯æ•°ç»„ï¼Œé€é¡¹åˆ—å‡º
                     value.forEach((item: any) => {
                         if (typeof item === 'string') {
                             formattedConflict += `- ${item}\n`;
                         } else {
                             formattedConflict += `- ${JSON.stringify(item, null, 2)}\n`;
                         }
                     });
                     formattedConflict += '\n';
                 } else if (typeof value === 'object') {
                     // å¦‚æœæ˜¯å¯¹è±¡ï¼Œè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
                     formattedConflict += `${JSON.stringify(value, null, 2)}\n\n`;
                 } else {
                     formattedConflict += `${String(value)}\n\n`;
                 }
             }
             
             worldStructure.centralConflict = formattedConflict.trim();
         }

         // å¤„ç†keyPlotPointså­—æ®µ
         if (Array.isArray(parsedResponse.keyPlotPoints)) {
             // å¦‚æœæ˜¯å­—ç¬¦ä¸²æ•°ç»„ï¼Œç›´æ¥ä½¿ç”¨
             if (parsedResponse.keyPlotPoints.every((item: any) => typeof item === 'string')) {
                 worldStructure.keyPlotPoints = parsedResponse.keyPlotPoints;
             } else {
                 // å¦‚æœæ˜¯å¯¹è±¡æ•°ç»„ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²æ•°ç»„
                 worldStructure.keyPlotPoints = parsedResponse.keyPlotPoints.map((point: any) => {
                     if (typeof point === 'string') {
                         return point;
                     } else if (typeof point === 'object') {
                         // å¦‚æœå¯¹è±¡æœ‰ç‰¹å®šå­—æ®µï¼Œç»„åˆæˆæ ¼å¼åŒ–çš„å­—ç¬¦ä¸²
                         if (point.åç§° && point.æ¢—æ¦‚) {
                             let formattedPoint = `${point.åç§°}: ${point.æ¢—æ¦‚}`;
                             // å¦‚æœè¿˜æœ‰å…¶ä»–å­—æ®µï¼Œä¹Ÿæ·»åŠ è¿›å»
                             if (point.å…³é”®è¦ç´  && Array.isArray(point.å…³é”®è¦ç´ )) {
                                 formattedPoint += `\nå…³é”®è¦ç´ :\n${point.å…³é”®è¦ç´ .map((elem: string) => `- ${elem}`).join('\n')}`;
                             }
                             return formattedPoint;
                         } else if (point.name && point.summary) {
                             return `${point.name}: ${point.summary}`;
                         } else {
                             // å…¶ä»–æƒ…å†µè½¬æ¢ä¸ºæ˜“è¯»çš„JSONå­—ç¬¦ä¸²
                             return JSON.stringify(point, null, 2);
                         }
                     } else {
                         return String(point);
                     }
                 });
             }
         }

         return worldStructure;
    }
};

export const generateFactions = async (config: NovelConfig, structure: WorldStructure, settings: AppSettings): Promise<{ factions: Faction[], regions: MapRegion[] }> => {
    const context = buildNovelContext(config);
    const prompt = `
      åŸºäºä»¥ä¸‹ä¸–ç•Œè§‚ï¼Œåˆ›å»ºåœ°ç†åŠ¿åŠ›åˆ†å¸ƒã€‚
      ${context}
      ä¸–ç•Œè§‚: ${structure.worldView}
      
      è¿”å› JSON å¯¹è±¡:
      - regions: 4-6ä¸ªåŒºåŸŸ (name, type=['continent'|'island'|'archipelago'], x(0-100), y(0-100))
      - factions: 4-6ä¸ªåŠ¿åŠ› (name, description, influence(1-10), color(hex), x(0-100), y(0-100))
    `;

    if (settings.provider === 'google') {
        const ai = getGoogleAI(settings);
        const response = await ai.models.generateContent({
            model: settings.model,
            contents: prompt,
            config: {
                responseMimeType: 'application/json',
                responseSchema: {
                    type: Type.OBJECT,
                    properties: {
                        regions: {
                             type: Type.ARRAY,
                             items: {
                                 type: Type.OBJECT,
                                 properties: {
                                     name: { type: Type.STRING },
                                     type: { type: Type.STRING },
                                     x: { type: Type.NUMBER },
                                     y: { type: Type.NUMBER }
                                 },
                                 required: ["name", "type", "x", "y"]
                             }
                        },
                        factions: {
                            type: Type.ARRAY,
                            items: {
                                type: Type.OBJECT,
                                properties: {
                                    name: { type: Type.STRING },
                                    description: { type: Type.STRING },
                                    influence: { type: Type.NUMBER },
                                    color: { type: Type.STRING },
                                    x: { type: Type.NUMBER },
                                    y: { type: Type.NUMBER }
                                },
                                required: ["name", "description", "influence", "color", "x", "y"]
                            }
                        }
                    },
                    required: ["regions", "factions"]
                }
            }
        });
        const raw = JSON.parse(response.text || "{}");
        const factions = (raw.factions || []).map((f: any) => ({ ...f, id: crypto.randomUUID() }));
        const regions = (raw.regions || []).map((r: any) => ({ ...r, id: crypto.randomUUID() }));
        return { factions, regions };
    } else {
        const res = await callOpenAI(
            settings.baseUrl || '',
            settings.apiKey,
            settings.model,
            [{role: 'user', content: prompt}],
            true
        );
        
        // å¤„ç†OpenAIæ ¼å¼çš„å“åº”
        let parsedResponse;
        if (typeof res === 'string') {
            // å¦‚æœæ˜¯æ™®é€šå­—ç¬¦ä¸²ï¼Œç›´æ¥è§£æ
            parsedResponse = JSON.parse(res);
        } else {
            // å¦‚æœæ˜¯å®Œæ•´çš„OpenAIå“åº”å¯¹è±¡ï¼ˆåŒ…å«choicesç­‰å­—æ®µï¼‰
            const responseObject = res as any;
            if (responseObject.choices && responseObject.choices[0] && responseObject.choices[0].message) {
                // æå–contentå­—æ®µå¹¶è§£æ
                const content = responseObject.choices[0].message.content;
                parsedResponse = JSON.parse(content);
            } else {
                // å…¶ä»–æƒ…å†µç›´æ¥è§£æ
                parsedResponse = JSON.parse(JSON.stringify(res));
            }
        }
        
        const factions = (parsedResponse.factions || []).map((f: any) => ({ 
            ...f, id: crypto.randomUUID(), 
            x: Number(f.x), y: Number(f.y), influence: Number(f.influence),
            color: f.color || '#000000'
        }));
        const regions = (parsedResponse.regions || []).map((r: any) => ({ 
            ...r, id: crypto.randomUUID(),
            x: Number(r.x), y: Number(r.y)
        }));
        return { factions, regions };
    }
};

export const generateCharacters = async (config: NovelConfig, settings: AppSettings, existing: Character[], structure: WorldStructure, count: number = 5): Promise<Character[]> => {
    const context = buildNovelContext(config);
    const prompt = `
        åŸºäºè®¾å®šå’Œç°æœ‰è§’è‰²ï¼Œåˆ›ä½œ ${count} ä¸ªæ–°è§’è‰²ã€‚
        ${context}
        ç°æœ‰è§’è‰²: ${existing.map(c => c.name).join(', ')}
        
        è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªè§’è‰²åŒ…å«: name, role, description, appearance, background, personality, relationships (æ•°ç»„: {targetName, relation}).
    `;

    if (settings.provider === 'google') {
        const ai = getGoogleAI(settings);
        const response = await ai.models.generateContent({
            model: settings.model,
            contents: prompt,
            config: {
                responseMimeType: 'application/json',
                responseSchema: {
                    type: Type.ARRAY,
                    items: {
                        type: Type.OBJECT,
                        properties: {
                            name: { type: Type.STRING },
                            role: { type: Type.STRING },
                            description: { type: Type.STRING },
                            appearance: { type: Type.STRING },
                            background: { type: Type.STRING },
                            personality: { type: Type.STRING },
                            relationships: { 
                                type: Type.ARRAY, 
                                items: { 
                                    type: Type.OBJECT,
                                    properties: { targetName: { type: Type.STRING }, relation: { type: Type.STRING } }
                                } 
                            }
                        }
                    }
                }
            }
        });
        const raw = JSON.parse(response.text || "[]");
        return raw.map((c: any) => ({
            ...c,
            id: crypto.randomUUID(),
            relationships: (c.relationships || []).map((r: any) => {
                const target = existing.find(ex => ex.name === r.targetName);
                return { targetId: target ? target.id : 'unknown', targetName: r.targetName, relation: r.relation };
            })
        }));
    } else {
        const res = await callOpenAI(
            settings.baseUrl || '', 
            settings.apiKey, 
            settings.model, 
            [{ role: 'user', content: prompt }],
            true
        );
        
        // å¤„ç†OpenAIæ ¼å¼çš„å“åº”
        let parsedResponse;
        if (typeof res === 'string') {
            // å¦‚æœæ˜¯æ™®é€šå­—ç¬¦ä¸²ï¼Œç›´æ¥è§£æ
            parsedResponse = JSON.parse(res);
        } else {
            // å¦‚æœæ˜¯å®Œæ•´çš„OpenAIå“åº”å¯¹è±¡ï¼ˆåŒ…å«choicesç­‰å­—æ®µï¼‰
            const responseObject = res as any;
            if (responseObject.choices && responseObject.choices[0] && responseObject.choices[0].message) {
                // æå–contentå­—æ®µå¹¶è§£æ
                const content = responseObject.choices[0].message.content;
                parsedResponse = JSON.parse(content);
            } else {
                // å…¶ä»–æƒ…å†µç›´æ¥è§£æ
                parsedResponse = JSON.parse(JSON.stringify(res));
            }
        }
        
        // æ£€æŸ¥è¿”å›çš„æ•°æ®ç»“æ„ï¼Œå¦‚æœæ˜¯åŒ…å«characterså­—æ®µçš„å¯¹è±¡ï¼Œåˆ™ä½¿ç”¨è¯¥å­—æ®µ
        const charactersArray = parsedResponse.characters || parsedResponse;
        
        return charactersArray.map((c: any) => ({
            ...c,
            id: crypto.randomUUID(),
            relationships: (c.relationships || []).map((r: any) => {
                const target = existing.find(ex => ex.name === r.targetName);
                return { targetId: target ? target.id : 'unknown', targetName: r.targetName, relation: r.relation };
            })
        }));
    }
};

export const generateRandomNames = async (config: NovelConfig, settings: AppSettings): Promise<string[]> => {
     const prompt = `ä¸º ${config.genre} ç±»å‹çš„å°è¯´ç”Ÿæˆ 5 ä¸ªåˆé€‚çš„è§’è‰²åå­—ã€‚
è¦æ±‚ï¼š
- åå­—è¦ç¬¦åˆå°è¯´ç±»å‹çš„é£æ ¼
- åå­—è¦æœ‰ç‰¹è‰²ï¼Œæ˜“äºè®°å¿†
- è¿”å› JSON å­—ç¬¦ä¸²æ•°ç»„æ ¼å¼`;
     
     if (settings.provider === 'google') {
         const ai = getGoogleAI(settings);
         const res = await ai.models.generateContent({
             model: settings.model,
             contents: prompt,
             config: { 
                 responseMimeType: 'application/json',
                 responseSchema: { type: Type.ARRAY, items: { type: Type.STRING } }
             }
         });
         return JSON.parse(res.text || "[]");
     }
     return ["å¼ ä¸‰", "æå››", "ç‹äº”"];
};

export const generateOutline = async (config: NovelConfig, characters: Character[], structure: WorldStructure, settings: AppSettings): Promise<Chapter[]> => {
    const context = buildNovelContext(config);
    const charSummary = characters.map(c => `${c.name} (${c.role})`).join(', ');
    const prompt = `
        åŸºäºè®¾å®šç”Ÿæˆå‰ 10 ç« å¤§çº²ã€‚
        ${context}
        å…³é”®è§’è‰²: ${charSummary}
        ä¸»çº¿å†²çª: ${structure.centralConflict}
        
        è¿”å› JSON æ•°ç»„: title, summary (100å­—), tension (1-10).
    `;

    if (settings.provider === 'google') {
        const ai = getGoogleAI(settings);
        const res = await ai.models.generateContent({
            model: settings.model,
            contents: prompt,
            config: {
                responseMimeType: 'application/json',
                responseSchema: {
                    type: Type.ARRAY,
                    items: {
                        type: Type.OBJECT,
                        properties: {
                            title: { type: Type.STRING },
                            summary: { type: Type.STRING },
                            tension: { type: Type.NUMBER }
                        }
                    }
                }
            }
        });
        const raw = JSON.parse(res.text || "[]");
        return raw.map((c: any, i: number) => ({
            id: crypto.randomUUID(),
            order: i + 1,
            title: c.title,
            summary: c.summary,
            tension: c.tension,
            content: "",
            wordCount: 0,
            parentId: null
        }));
    } else {
        const res = await callOpenAI(
            settings.baseUrl || '', 
            settings.apiKey, 
            settings.model, 
            [{ role: 'user', content: prompt }],
            true
        );
        
        // å¤„ç†OpenAIæ ¼å¼çš„å“åº”
        let parsedResponse;
        if (typeof res === 'string') {
            // å¦‚æœæ˜¯æ™®é€šå­—ç¬¦ä¸²ï¼Œç›´æ¥è§£æ
            parsedResponse = JSON.parse(res);
        } else {
            // å¦‚æœæ˜¯å®Œæ•´çš„OpenAIå“åº”å¯¹è±¡ï¼ˆåŒ…å«choicesç­‰å­—æ®µï¼‰
            const responseObject = res as any;
            if (responseObject.choices && responseObject.choices[0] && responseObject.choices[0].message) {
                // æå–contentå­—æ®µå¹¶è§£æ
                const content = responseObject.choices[0].message.content;
                parsedResponse = JSON.parse(content);
            } else {
                // å…¶ä»–æƒ…å†µç›´æ¥è§£æ
                parsedResponse = JSON.parse(JSON.stringify(res));
            }
        }
        
        // æ£€æŸ¥è¿”å›çš„æ•°æ®ç»“æ„ï¼Œå¦‚æœæ˜¯åŒ…å«chapterså­—æ®µçš„å¯¹è±¡ï¼Œåˆ™ä½¿ç”¨è¯¥å­—æ®µ
        const chaptersArray = parsedResponse.chapters || parsedResponse;
        
        return chaptersArray.map((c: any, i: number) => ({
            id: crypto.randomUUID(),
            order: i + 1,
            title: c.title,
            summary: c.summary,
            tension: c.tension,
            content: "",
            wordCount: 0,
            parentId: null
        }));
    }
};

export const extendOutline = async (config: NovelConfig, characters: Character[], currentChapters: Chapter[], settings: AppSettings, structure: WorldStructure): Promise<Chapter[]> => {
    // Basic logic to generate next chapters based on last one
    const context = buildNovelContext(config);
    const lastChapter = currentChapters[currentChapters.length - 1];
    const prompt = `
        ${context}
        Previous Chapter: ${lastChapter.title} - ${lastChapter.summary}
        Generate next 5 chapters. Return JSON array: title, summary, tension.
    `;
    
    // Reuse generateOutline logic structure but with new prompt
    if (settings.provider === 'google') {
        const ai = getGoogleAI(settings);
        const res = await ai.models.generateContent({
            model: settings.model,
            contents: prompt,
            config: {
                responseMimeType: 'application/json',
                responseSchema: {
                    type: Type.ARRAY,
                    items: {
                        type: Type.OBJECT,
                        properties: {
                            title: { type: Type.STRING },
                            summary: { type: Type.STRING },
                            tension: { type: Type.NUMBER }
                        }
                    }
                }
            }
        });
        const raw = JSON.parse(res.text || "[]");
        let startOrder = currentChapters.length + 1;
        return raw.map((c: any) => ({
            id: crypto.randomUUID(),
            order: startOrder++,
            title: c.title,
            summary: c.summary,
            tension: c.tension,
            content: "",
            wordCount: 0,
            parentId: null
        }));
    }
    return [];
};

/**
 * Enhanced generateChapterBeats function with deep context support.
 * 
 * Requirements: 2.1, 2.2, 3.1, 3.2, 3.3, 3.4, 3.5
 * - Injects volume context (summary, core conflict, progress) for chapters in volumes
 * - Extracts last 500 characters from previous chapter for continuity
 * - Reads and injects hooks from previous chapter
 * - Builds ancestor summaries for branching narratives
 * - Returns 5-8 specific plot beats
 * 
 * @param chapter - The chapter to generate beats for
 * @param allChapters - All chapters in the project (for finding previous chapter and ancestors)
 * @param volumes - All volumes in the project (for volume context injection)
 * @param config - Novel configuration
 * @param characters - All characters in the project
 * @param settings - App settings including API configuration
 * @returns Array of 5-8 plot beat strings
 */
/**
 * Enhanced generateChapterBeats function with deep context support and plot loop integration.
 * 
 * Requirements: 2.1, 2.2, 3.1, 3.2, 3.3, 3.4, 3.5, 4.1, 4.2, 4.4
 * - Injects volume context (summary, core conflict, progress) for chapters in volumes
 * - Extracts last 500 characters from previous chapter for continuity
 * - Reads and injects hooks from previous chapter
 * - Builds ancestor summaries for branching narratives
 * - Injects all OPEN and URGENT plot loops into the AI prompt context (Requirement 4.1)
 * - Instructs AI to prioritize URGENT plot loops (Requirement 4.2)
 * - Includes relevant OPEN plot loops for narrative continuity (Requirement 4.4)
 * - Returns 5-8 specific plot beats
 * 
 * @param chapter - The chapter to generate beats for
 * @param allChapters - All chapters in the project (for finding previous chapter and ancestors)
 * @param volumes - All volumes in the project (for volume context injection)
 * @param config - Novel configuration
 * @param characters - All characters in the project
 * @param settings - App settings including API configuration
 * @param plotLoops - All plot loops in the project (optional, for plot loop context injection)
 * @returns Array of 5-8 plot beat strings
 */
export const generateChapterBeats = async (
    chapter: Chapter, 
    allChapters: Chapter[], 
    volumes: Volume[],
    config: NovelConfig, 
    characters: Character[], 
    settings: AppSettings,
    plotLoops: PlotLoop[] = []
): Promise<string[]> => {
    const context = buildNovelContext(config);
    
    // === 1. Find previous chapter and extract last content (Requirement 3.1) ===
    const previousChapter = findPreviousChapter(chapter, allChapters);
    const lastContent = previousChapter ? extractLastContent(previousChapter, 500) : '';
    
    // === 2. Extract hooks from previous chapter (Requirements 3.2, 3.3) ===
    const hooks = previousChapter?.hooks || [];
    
    // === 3. Build ancestor summaries for branching narratives (Requirement 3.4) ===
    const ancestors = getVolumeChapterAncestors(chapter.id, allChapters);
    const ancestorSummaries = ancestors.length > 0 
        ? ancestors.map(a => `ç¬¬${a.order}ç«  ${a.title}: ${a.summary}`).join('\n')
        : '';
    
    // === 4. Build volume context (Requirements 2.1, 2.2, 2.5) ===
    let volumeContext = '';
    if (chapter.volumeId) {
        const volume = volumes.find(v => v.id === chapter.volumeId);
        if (volume) {
            // Calculate progress within volume
            const progress = getVolumeProgress(chapter, volumes, allChapters);
            const progressText = progress 
                ? `æœ¬å·è¿›åº¦: ç¬¬ ${progress.position}/${progress.total} ç«  (${progress.percentage.toFixed(0)}%)`
                : '';
            
            volumeContext = `
å½“å‰åˆ†å·: ${volume.title}
åˆ†å·æ‘˜è¦: ${volume.summary}
æ ¸å¿ƒå†²çª: ${volume.coreConflict}
${progressText}`;
            
            // Check if this is the first chapter of a new volume and previous volume has summary (Requirement 2.5)
            if (progress && progress.position === 1 && volume.order > 1) {
                const previousVolume = volumes.find(v => v.order === volume.order - 1);
                if (previousVolume?.volumeSummary) {
                    volumeContext += `\n\nä¸Šä¸€å·æ€»ç»“: ${previousVolume.volumeSummary}`;
                }
            }
        }
    }
    
    // === 5. Build plot loop context (Requirements 4.1, 4.2, 4.4) ===
    const plotLoopContext = buildLoopContextForPrompt(chapter.id, plotLoops);
    
    // === 6. Build enhanced prompt (Requirement 3.5) ===
    const prompt = `
${context}

${volumeContext ? `=== åˆ†å·ä¿¡æ¯ ===\n${volumeContext}\n` : ''}

${plotLoopContext ? `\n${plotLoopContext}\n` : ''}

ä¸ºç« èŠ‚ "${chapter.title}" è®¾è®¡è¯¦ç»†çš„å‰§æƒ…ç»†çº² (Beats)ã€‚
ç« èŠ‚æ‘˜è¦: ${chapter.summary}

${ancestorSummaries ? `=== å‰ç½®å‰§æƒ… ===\n${ancestorSummaries}\n` : ''}

${lastContent ? `=== ä¸Šä¸€ç« ç»“å°¾ ===\n${lastContent}\n` : ''}

${hooks.length > 0 ? `=== éœ€è¦å›åº”çš„ä¼ç¬” ===\n${hooks.map((h, i) => `${i + 1}. ${h}`).join('\n')}\n` : ''}

=== è¦æ±‚ ===
1. ç”Ÿæˆ 5-8 ä¸ªå…·ä½“çš„å‰§æƒ…æ­¥éª¤
2. æ¯ä¸ªæ­¥éª¤åº”åŒ…å«å…·ä½“çš„åœºæ™¯ã€åŠ¨ä½œæˆ–å¯¹è¯è¦ç‚¹
3. ç¡®ä¿ä¸ä¸Šä¸€ç« è‡ªç„¶è¡”æ¥${lastContent ? 'ï¼Œæ‰¿æ¥ä¸Šæ–‡çš„æƒ…èŠ‚å‘å±•' : ''}
4. é¿å…ä¸å‰æ–‡é‡å¤çš„æƒ…èŠ‚æˆ–æå†™
${hooks.length > 0 ? `5. å¿…é¡»å›åº”ä¸Šè¿°ä¼ç¬”ï¼Œåœ¨ç»†çº²ä¸­ä½“ç°å¯¹è¿™äº›æ‚¬å¿µçš„å¤„ç†` : ''}
${volumeContext ? `6. ç¬¦åˆåˆ†å·çš„æ•´ä½“èŠ‚å¥å’Œæ ¸å¿ƒå†²çª` : ''}
${plotLoopContext ? `7. åœ¨ç»†çº²ä¸­è‡ªç„¶åœ°æ¨è¿›æˆ–å›æ”¶ä¸Šè¿°ä¼ç¬”è¿½è¸ªä¸­çš„æ‚¬å¿µ` : ''}

è¿”å› JSON å­—ç¬¦ä¸²æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå…·ä½“çš„æƒ…èŠ‚æ­¥éª¤ã€‚
    `.trim();
    
    // ğŸ†• æ£€æŸ¥ Token é¢„ç®—
    const estimatedTokens = tokenCounter.estimateTokens(prompt) + 500; // é¢„ä¼°è¾“å‡º 500 tokens
    const canProceed = await tokenCounter.checkBudget(estimatedTokens, settings.tokenBudget);
    if (!canProceed) {
        throw new Error('Token budget exceeded');
    }
    
    let result: string[] = [];
    
    if (settings.provider === 'google') {
        const ai = getGoogleAI(settings);
        const res = await ai.models.generateContent({
            model: settings.model,
            contents: prompt,
            config: {
                responseMimeType: 'application/json',
                responseSchema: { type: Type.ARRAY, items: { type: Type.STRING } }
            }
        });
        result = JSON.parse(res.text || "[]");
    } else {
        // ğŸ†• æ”¯æŒå…¶ä»–æä¾›å•†
        const systemPrompt = 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´å¤§çº²è®¾è®¡å¸ˆã€‚è¯·ä¸¥æ ¼è¿”å› JSON æ ¼å¼çš„å­—ç¬¦ä¸²æ•°ç»„ï¼Œä¾‹å¦‚ï¼š["æ­¥éª¤1", "æ­¥éª¤2", "æ­¥éª¤3"]';
        const res = await callOpenAI(
            settings.baseUrl || '',
            settings.apiKey,
            settings.model,
            [
                { role: 'system', content: systemPrompt },
                { role: 'user', content: prompt }
            ],
            true
        );
        
        try {
            // å¤„ç†å¯èƒ½çš„å“åº”æ ¼å¼
            let parsed: any;
            
            if (typeof res === 'string') {
                parsed = JSON.parse(res);
            } else {
                parsed = res;
            }
            
            // ğŸ†• å¤„ç†å¤æ‚çš„åµŒå¥—ç»“æ„
            if (Array.isArray(parsed)) {
                // å¦‚æœæ˜¯æ•°ç»„ï¼Œæ£€æŸ¥å…ƒç´ ç±»å‹
                if (parsed.length > 0 && typeof parsed[0] === 'object') {
                    // å¦‚æœæ˜¯å¯¹è±¡æ•°ç»„ï¼Œæå– summary æˆ– title å­—æ®µ
                    result = parsed.map((item: any) => {
                        if (typeof item === 'string') return item;
                        return item.summary || item.title || item.content || JSON.stringify(item);
                    });
                } else {
                    // å¦‚æœæ˜¯å­—ç¬¦ä¸²æ•°ç»„ï¼Œç›´æ¥ä½¿ç”¨
                    result = parsed.map((item: any) => String(item));
                }
            } else if (parsed && typeof parsed === 'object') {
                // ğŸ†• å¤„ç† { beats: [...] } æ ¼å¼
                if (parsed.beats && Array.isArray(parsed.beats)) {
                    result = parsed.beats.map((item: any) => {
                        if (typeof item === 'string') return item;
                        // æå–æœ‰æ„ä¹‰çš„å­—æ®µ
                        if (item.summary) return item.summary;
                        if (item.title) return item.title;
                        if (item.content) return item.content;
                        // å¦‚æœæœ‰ details æ•°ç»„ï¼Œåˆå¹¶æˆä¸€ä¸ªå­—ç¬¦ä¸²
                        if (item.details && Array.isArray(item.details)) {
                            return item.details.join(' ');
                        }
                        return JSON.stringify(item);
                    });
                } else {
                    // å°è¯•æå–å¯¹è±¡ä¸­çš„æ•°ç»„å­—æ®µ
                    const arrayField = Object.values(parsed).find((v: any) => Array.isArray(v));
                    if (arrayField && Array.isArray(arrayField)) {
                        result = arrayField.map((item: any) => 
                            typeof item === 'string' ? item : (item.summary || item.title || JSON.stringify(item))
                        );
                    } else {
                        result = [];
                    }
                }
            } else {
                result = [];
            }
            
            // ç¡®ä¿ç»“æœæ˜¯å­—ç¬¦ä¸²æ•°ç»„
            result = result.filter((item: any) => item && typeof item === 'string' && item.trim().length > 0);
            
            if (result.length === 0) {
                console.warn('è§£æåçš„ç»†çº²ä¸ºç©ºï¼ŒåŸå§‹å“åº”:', res);
            }
        } catch (e) {
            console.error('Failed to parse beats response:', e);
            console.error('Raw response:', res);
            result = [];
        }
    }
    
    // ğŸ†• è®°å½• Token ä½¿ç”¨
    tokenCounter.record(prompt, JSON.stringify(result), settings.model, 'beats_generation');
    
    return result;
};

/**
 * Generates a comprehensive summary for a completed volume.
 * 
 * Requirements: 2.3, 2.4
 * - Generates a 500-1000 word summary based on all chapter summaries in the volume
 * - Captures key plot developments, character arcs, and major events
 * - Returns the summary text to be saved to Volume.volumeSummary
 * 
 * @param volume - The volume to generate summary for
 * @param chapters - All chapters in the project
 * @param config - Novel configuration
 * @param settings - App settings including API configuration
 * @returns Summary text (500-1000 words)
 */
export const generateVolumeSummary = async (
    volume: Volume,
    chapters: Chapter[],
    config: NovelConfig,
    settings: AppSettings
): Promise<string> => {
    // Get chapters that belong to this volume, sorted by order
    const volumeChapters = chapters
        .filter(chapter => volume.chapterIds.includes(chapter.id))
        .sort((a, b) => a.order - b.order);
    
    // If no chapters, return empty string
    if (volumeChapters.length === 0) {
        return '';
    }
    
    // Build chapter summaries for the prompt
    const chapterSummaries = volumeChapters
        .map(c => `ç¬¬${c.order}ç«  ${c.title}: ${c.summary}`)
        .join('\n');
    
    const context = buildNovelContext(config);
    
    const prompt = `
${context}

=== åˆ†å·ä¿¡æ¯ ===
åˆ†å·æ ‡é¢˜: ${volume.title}
åˆ†å·æ‘˜è¦: ${volume.summary}
æ ¸å¿ƒå†²çª: ${volume.coreConflict}
ç« èŠ‚æ•°é‡: ${volumeChapters.length}

=== å„ç« èŠ‚æ‘˜è¦ ===
${chapterSummaries}

=== ä»»åŠ¡ ===
è¯·åŸºäºä»¥ä¸Šç« èŠ‚æ‘˜è¦ï¼Œä¸ºæœ¬å·ç”Ÿæˆä¸€ä»½è¯¦ç»†çš„å›é¡¾æ€»ç»“ã€‚

=== è¦æ±‚ ===
1. æ€»ç»“å­—æ•°æ§åˆ¶åœ¨ 500-1000 å­—
2. æ¶µç›–æœ¬å·çš„ä¸»è¦å‰§æƒ…å‘å±•è„‰ç»œ
3. çªå‡ºé‡è¦çš„è§’è‰²æˆé•¿å’Œå…³ç³»å˜åŒ–
4. è®°å½•å…³é”®çš„è½¬æŠ˜ç‚¹å’Œé«˜æ½®åœºæ™¯
5. æ€»ç»“æœ¬å·è§£å†³çš„å†²çªå’Œç•™ä¸‹çš„æ‚¬å¿µ
6. ä¸ºä¸‹ä¸€å·çš„å‰§æƒ…å‘å±•åšå¥½é“ºå«å’Œæš—ç¤º
7. ä½¿ç”¨æµç•…çš„å™è¿°æ€§è¯­è¨€ï¼Œè€Œéç®€å•ç½—åˆ—

è¯·ç›´æ¥è¾“å‡ºæ€»ç»“å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•å‰ç¼€æˆ–æ ‡é¢˜ã€‚
    `.trim();
    
    // Check token budget
    const estimatedTokens = tokenCounter.estimateTokens(prompt) + 1000; // Estimate 1000 tokens for output
    const canProceed = await tokenCounter.checkBudget(estimatedTokens, settings.tokenBudget);
    if (!canProceed) {
        throw new Error('Token budget exceeded');
    }
    
    let result = '';
    
    if (settings.provider === 'google') {
        const ai = getGoogleAI(settings);
        const res = await ai.models.generateContent({
            model: settings.model,
            contents: prompt
        });
        result = res.text || '';
    } else {
        const systemPrompt = 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´ç¼–è¾‘ï¼Œæ“…é•¿æ€»ç»“å’Œæç‚¼å‰§æƒ…è¦ç‚¹ã€‚è¯·ç”Ÿæˆæµç•…ã€æœ‰æ¡ç†çš„åˆ†å·æ€»ç»“ã€‚';
        result = await callOpenAI(
            settings.baseUrl || '',
            settings.apiKey,
            settings.model,
            [
                { role: 'system', content: systemPrompt },
                { role: 'user', content: prompt }
            ]
        );
    }
    
    // Record token usage
    tokenCounter.record(prompt, result, settings.model, 'volume_summary');
    
    return result;
};

/**
 * Streams chapter content generation with plot loop context injection.
 * 
 * Requirements: 4.1, 4.4
 * - Includes relevant OPEN plot loops as context for narrative continuity
 * - Injects all OPEN and URGENT plot loops into the AI prompt context
 * 
 * @param chapter - The chapter to generate content for
 * @param allChapters - All chapters in the project
 * @param config - Novel configuration
 * @param characters - All characters in the project
 * @param settings - App settings including API configuration
 * @param structure - World structure
 * @param volumes - All volumes in the project
 * @param plotLoops - All plot loops in the project (optional, for plot loop context injection)
 */
export const streamChapterContent = async function* (chapter: Chapter, allChapters: Chapter[], config: NovelConfig, characters: Character[], settings: AppSettings, structure: WorldStructure, volumes: Volume[] = [], plotLoops: PlotLoop[] = []) {
    const context = buildNovelContext(config);
    
    // ğŸ†• ä½¿ç”¨ RAG æ£€ç´¢ç›¸å…³ç« èŠ‚ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    let prevSummary = '';
    if (settings.useRAG && allChapters.length > 5) {
        try {
            const relevantChapters = await retrieveRelevantChapters(
                chapter.summary,
                allChapters,
                settings,
                3,
                chapter.id
            );
            prevSummary = relevantChapters.map(c => 
                `ç¬¬${c.order}ç«  ${c.title}: ${c.summary}`
            ).join('\n');
        } catch (e) {
            console.warn('RAG retrieval failed, falling back to sequential:', e);
            // é™çº§ï¼šä½¿ç”¨ä¼ ç»Ÿçš„é¡ºåºæ–¹å¼
            const ancestors = getChapterAncestors(chapter.id, allChapters);
            prevSummary = ancestors.slice(-3).map(c => 
                `ç¬¬${c.order}ç«  ${c.title}: ${c.summary}`
            ).join('\n');
        }
    } else {
        // ä¼ ç»Ÿæ–¹å¼ï¼šå–æœ€è¿‘ 3 ç« 
        const ancestors = getChapterAncestors(chapter.id, allChapters);
        prevSummary = ancestors.slice(-3).map(c => 
            `ç¬¬${c.order}ç«  ${c.title}: ${c.summary}`
        ).join('\n');
    }
    
    // ğŸ†• ä½¿ç”¨ RAG æ£€ç´¢ç›¸å…³è§’è‰²ï¼ˆå¦‚æœå¯ç”¨ä¸”æœ‰è§’è‰²ï¼‰
    let charContext = '';
    if (settings.useRAG && characters.length > 5) {
        try {
            const relevantCharacters = await retrieveRelevantCharacters(
                chapter.summary,
                characters,
                settings,
                5
            );
            charContext = relevantCharacters.map(c =>
                `${c.name}(${c.role}): ${c.description.slice(0, 100)}`
            ).join('\n');
        } catch (e) {
            console.warn('Character RAG retrieval failed:', e);
        }
    }

    // ğŸ†• æ„å»ºåˆ†å·ä¸Šä¸‹æ–‡
    let volumeContext = '';
    if (chapter.volumeId && volumes.length > 0) {
        const volume = volumes.find(v => v.id === chapter.volumeId);
        if (volume) {
            const volumeChapters = allChapters.filter(c => c.volumeId === volume.id);
            const position = volumeChapters.filter(c => c.order <= chapter.order).length;
            volumeContext = `
å½“å‰åˆ†å·: ${volume.title}
åˆ†å·æ ¸å¿ƒå†²çª: ${volume.coreConflict}
æœ¬å·è¿›åº¦: ç¬¬ ${position}/${volumeChapters.length} ç« `;
        }
    }

    // ğŸ†• è·å–ä¸Šä¸€ç« çš„ä¼ç¬”
    const previousChapter = findPreviousChapter(chapter, allChapters);
    const hooksToResolve = previousChapter?.hooks || [];
    
    // ğŸ†• æ„å»ºä¼ç¬”è¿½è¸ªä¸Šä¸‹æ–‡ (Requirements 4.1, 4.4)
    const plotLoopContext = buildLoopContextForPrompt(chapter.id, plotLoops);
    
    const beats = (chapter.beats || []).join('\n- ');
    
    const prompt = `
æ’°å†™ç¬¬ ${chapter.order} ç« : ${chapter.title}ã€‚

${context}
${volumeContext ? `\n=== åˆ†å·èƒŒæ™¯ ===${volumeContext}\n` : ''}
${prevSummary ? `\n=== ç›¸å…³å‰æƒ… ===\n${prevSummary}\n` : ''}
${charContext ? `\n=== ç›¸å…³è§’è‰² ===\n${charContext}\n` : ''}
${hooksToResolve.length > 0 ? `\n=== éœ€è¦å›åº”çš„ä¼ç¬” ===\n${hooksToResolve.map((h, i) => `${i + 1}. ${h}`).join('\n')}\n` : ''}
${plotLoopContext ? `\n${plotLoopContext}\n` : ''}

=== æœ¬ç« ä»»åŠ¡ ===
ç« èŠ‚æ‘˜è¦: ${chapter.summary}
${beats ? `ç»†çº²æ­¥éª¤:\n- ${beats}` : ''}

=== å†™ä½œè¦æ±‚ ===
1. ç½‘æ–‡é£æ ¼ï¼ŒèŠ‚å¥ç´§å‡‘ï¼Œæå†™ç”ŸåŠ¨
2. å¯¹è¯è‡ªç„¶æµç•…ï¼Œç¬¦åˆè§’è‰²æ€§æ ¼
3. åœºæ™¯æå†™ç»†è…»ï¼Œç”»é¢æ„Ÿå¼º
4. æƒ…èŠ‚æ¨è¿›åˆç†ï¼Œä¸æ‹–æ²“
${hooksToResolve.length > 0 ? '5. å¿…é¡»è‡ªç„¶åœ°å›åº”ä¸Šè¿°ä¼ç¬”ï¼Œæ¨è¿›æ‚¬å¿µçš„è§£å†³' : ''}
${volumeContext ? '6. ç¬¦åˆå½“å‰åˆ†å·çš„æ ¸å¿ƒå†²çªå’Œæ•´ä½“èŠ‚å¥' : ''}
${plotLoopContext ? '7. åœ¨å†…å®¹ä¸­è‡ªç„¶åœ°æ¨è¿›æˆ–å›æ”¶ä¼ç¬”è¿½è¸ªä¸­çš„æ‚¬å¿µ' : ''}

=== æ’ç‰ˆæ ¼å¼ ===
- æ¯ä¸ªè‡ªç„¶æ®µä¹‹é—´ç©ºä¸€è¡Œ
- æ¯å¥å¯¹è¯å•ç‹¬æˆæ®µ
- åœºæ™¯åˆ‡æ¢æ—¶ç©ºä¸¤è¡Œ
- æ¯æ®µ 2-4 å¥è¯ï¼Œé¿å…å¤§æ®µæ–‡å­—
- ä½¿ç”¨ä¸­æ–‡æ ‡ç‚¹ï¼Œå¯¹è¯ç”¨åŒå¼•å·

=== è¾“å‡ºè¦æ±‚ ===
- ç›´æ¥è¾“å‡ºæ­£æ–‡å†…å®¹ï¼Œä¸è¦ä»»ä½•å‰ç¼€æˆ–è¯´æ˜
- å­—æ•°æ§åˆ¶åœ¨ 2000-3000 å­—
- ç¡®ä¿æ®µè½ä¹‹é—´æœ‰æ˜ç¡®çš„ç©ºè¡Œåˆ†éš”
    `.trim();

    // ğŸ†• æ£€æŸ¥ Token é¢„ç®—
    const estimatedTokens = tokenCounter.estimateTokens(prompt) + 3000; // é¢„ä¼°è¾“å‡º 3000 tokens
    const canProceed = await tokenCounter.checkBudget(estimatedTokens, settings.tokenBudget);
    if (!canProceed) {
        throw new Error('Token budget exceeded');
    }

    let fullOutput = '';
    
    if (settings.provider === 'google') {
        const ai = getGoogleAI(settings);
        const result = await ai.models.generateContentStream({
            model: settings.model,
            contents: prompt
        });
        for await (const chunk of result) {
            fullOutput += chunk.text;
            yield { text: chunk.text };
        }
    } else {
        const text = await callOpenAI(settings.baseUrl || '', settings.apiKey, settings.model, [{role: 'user', content: prompt}]);
        fullOutput = text;
        yield { text };
    }
    
    // ğŸ†• è®°å½• Token ä½¿ç”¨
    tokenCounter.record(prompt, fullOutput, settings.model, 'chapter_generation');
};

export const streamTextPolish = async function* (text: string, instruction: string, contextBefore: string, contextAfter: string, settings: AppSettings, config: NovelConfig) {
    const prompt = `
        Instruction: ${instruction}
        Context Before: ...${contextBefore.slice(-200)}
        Text to Polish: "${text}"
        Context After: ${contextAfter.slice(0, 200)}...
        
        Only output the polished text.
    `;
    
    // ğŸ†• æ£€æŸ¥ Token é¢„ç®—
    const estimatedTokens = tokenCounter.estimateTokens(prompt) + tokenCounter.estimateTokens(text);
    const canProceed = await tokenCounter.checkBudget(estimatedTokens, settings.tokenBudget);
    if (!canProceed) {
        throw new Error('Token budget exceeded');
    }

    let fullOutput = '';
    
    if (settings.provider === 'google') {
        const ai = getGoogleAI(settings);
        const result = await ai.models.generateContentStream({
            model: settings.model,
            contents: prompt
        });
        for await (const chunk of result) {
            fullOutput += chunk.text;
            yield { text: chunk.text };
        }
    } else {
         const res = await callOpenAI(settings.baseUrl||'', settings.apiKey, settings.model, [{role:'user', content: prompt}]);
         fullOutput = res;
         yield { text: res };
    }
    
    // ğŸ†• è®°å½• Token ä½¿ç”¨
    tokenCounter.record(prompt, fullOutput, settings.model, 'polish');
};

// --- RAG ---

export const analyzeChapterForWiki = async (content: string, existingNames: string[], settings: AppSettings, config: NovelConfig): Promise<WikiEntry[]> => {
    const prompt = `
        Analyze the text and extract new Wiki Entries (Items, Skills, Locations, Persons, Organizations).
        Ignore these existing entries: ${existingNames.join(', ')}.
        Text: ${content.slice(0, 10000)}...
        
        Return JSON array: name, category, description.
    `;
    
    if (settings.provider === 'google') {
        const ai = getGoogleAI(settings);
        const res = await ai.models.generateContent({
            model: settings.model,
            contents: prompt,
            config: {
                responseMimeType: 'application/json',
                responseSchema: {
                    type: Type.ARRAY,
                    items: {
                        type: Type.OBJECT,
                        properties: {
                            name: { type: Type.STRING },
                            category: { type: Type.STRING },
                            description: { type: Type.STRING }
                        }
                    }
                }
            }
        });
        const raw = JSON.parse(res.text || "[]");
        return raw.map((r: any) => ({ ...r, id: crypto.randomUUID() }));
    }
    return [];
};

export const indexContent = async (record: Partial<VectorRecord>, settings: AppSettings) => {
    // 1. Generate Embedding
    if (settings.provider === 'google') {
        const ai = getGoogleAI(settings);
        const model = "text-embedding-004";
        const result = await ai.models.embedContent({
            model,
            contents: record.text || ""
        });
        const vector = result.embeddings?.[0]?.values || [];
        
        // 2. Save to DB
        if (vector) {
            await db.saveVectors([{
                id: crypto.randomUUID(),
                relatedId: record.id || '',
                type: record.type as any,
                text: record.text || '',
                vector: vector,
                timestamp: Date.now(),
                metadata: record.metadata
            }]);
        }
    }
};

// --- Chat ---

/**
 * ğŸ†• åŠ¨æ€æ„å»ºç³»ç»Ÿæç¤ºï¼ˆæ ¹æ®ç”¨æˆ·é—®é¢˜æ³¨å…¥ç›¸å…³ä¸Šä¸‹æ–‡ï¼‰
 */
function buildDynamicSystemPrompt(
    config: NovelConfig,
    userMsg: string,
    characters: Character[],
    structure: WorldStructure,
    chapters: Chapter[]
): string {
    let context = `You are the AI Editor for the novel "${config.title}". 
    Genre: ${config.genre}. 
    ${buildNovelContext(config)}`;
    
    // å¦‚æœé—®é¢˜æ¶‰åŠè§’è‰²ï¼Œæ³¨å…¥è§’è‰²ä¿¡æ¯
    if (userMsg.match(/è§’è‰²|äººç‰©|character|ä¸»è§’|é…è§’/i)) {
        const charSummary = characters.slice(0, 8).map(c => 
            `${c.name}(${c.role}): ${c.description.slice(0, 150)}`
        ).join('\n');
        if (charSummary) {
            context += `\n\nä¸»è¦è§’è‰²:\n${charSummary}`;
        }
    }
    
    // å¦‚æœé—®é¢˜æ¶‰åŠå‰§æƒ…ï¼Œæ³¨å…¥æœ€è¿‘ç« èŠ‚æ‘˜è¦
    if (userMsg.match(/å‰§æƒ…|æƒ…èŠ‚|plot|chapter|ç« èŠ‚|æ•…äº‹/i)) {
        const recentChapters = chapters.slice(-8).map(c =>
            `ç¬¬${c.order}ç«  ${c.title}: ${c.summary.slice(0, 100)}`
        ).join('\n');
        if (recentChapters) {
            context += `\n\næœ€è¿‘ç« èŠ‚:\n${recentChapters}`;
        }
    }
    
    // å¦‚æœé—®é¢˜æ¶‰åŠä¸–ç•Œè§‚ï¼Œæ³¨å…¥ä¸–ç•Œè§‚ä¿¡æ¯
    if (userMsg.match(/ä¸–ç•Œ|è®¾å®š|èƒŒæ™¯|åŠ¿åŠ›|åœ°å›¾|world/i)) {
        if (structure.worldView) {
            context += `\n\nä¸–ç•Œè§‚: ${structure.worldView.slice(0, 500)}`;
        }
        if (structure.centralConflict) {
            context += `\næ ¸å¿ƒå†²çª: ${structure.centralConflict.slice(0, 200)}`;
        }
    }
    
    context += `\n\nAnswer questions about plot, characters, or logic. Be concise and helpful.`;
    
    return context;
}

/**
 * ğŸ†• ç”Ÿæˆå¯¹è¯å†å²æ‘˜è¦
 */
async function summarizeConversationHistory(
    history: OpenAIMessage[],
    settings: AppSettings
): Promise<string> {
    if (history.length === 0) return '';
    
    const historyText = history.map(h => `${h.role}: ${h.content}`).join('\n');
    const prompt = `Summarize the following conversation in 2-3 sentences, focusing on key points discussed:\n\n${historyText}`;
    
    try {
        if (settings.provider === 'google') {
            const ai = getGoogleAI(settings);
            const result = await ai.models.generateContent({
                model: settings.model,
                contents: prompt
            });
            return result.text || '';
        } else {
            return await callOpenAI(
                settings.baseUrl || '',
                settings.apiKey,
                settings.model,
                [{ role: 'user', content: prompt }]
            );
        }
    } catch (e) {
        console.error('Failed to summarize conversation:', e);
        return '';
    }
}

export const streamProjectChat = async function* (history: OpenAIMessage[], userMsg: string, config: NovelConfig, characters: Character[], structure: WorldStructure, chapters: Chapter[], settings: AppSettings) {
    // ğŸ†• é™åˆ¶å†å²è®°å½•é•¿åº¦ï¼ˆæ»‘åŠ¨çª—å£ï¼‰
    const MAX_HISTORY_TURNS = 10; // åªä¿ç•™æœ€è¿‘ 10 è½®å¯¹è¯
    let contextHistory = history.slice(-MAX_HISTORY_TURNS);
    
    // ğŸ†• å¦‚æœå†å²è®°å½•è¿‡é•¿ï¼Œç”Ÿæˆæ—©æœŸå¯¹è¯çš„æ‘˜è¦
    let earlySummary = '';
    if (history.length > MAX_HISTORY_TURNS) {
        const earlyHistory = history.slice(0, -MAX_HISTORY_TURNS);
        earlySummary = await summarizeConversationHistory(earlyHistory, settings);
    }
    
    // ğŸ†• åŠ¨æ€æ„å»ºç³»ç»Ÿæç¤ºï¼ˆæ ¹æ®ç”¨æˆ·é—®é¢˜æ³¨å…¥ç›¸å…³ä¸Šä¸‹æ–‡ï¼‰
    const systemPrompt = buildDynamicSystemPrompt(config, userMsg, characters, structure, chapters);
    
    // ğŸ†• å¦‚æœæœ‰æ—©æœŸå¯¹è¯æ‘˜è¦ï¼Œæ·»åŠ åˆ°ä¸Šä¸‹æ–‡
    const fullSystemPrompt = earlySummary 
        ? `${systemPrompt}\n\nEarlier conversation summary: ${earlySummary}`
        : systemPrompt;

    // ğŸ†• æ£€æŸ¥ Token é¢„ç®—
    const estimatedInput = tokenCounter.estimateTokens(
        fullSystemPrompt + contextHistory.map(h => h.content).join('') + userMsg
    );
    const estimatedTokens = estimatedInput + 500; // é¢„ä¼°è¾“å‡º 500 tokens
    const canProceed = await tokenCounter.checkBudget(estimatedTokens, settings.tokenBudget);
    if (!canProceed) {
        throw new Error('Token budget exceeded');
    }

    let fullOutput = '';

    if (settings.provider === 'google') {
        const ai = getGoogleAI(settings);
        // Gemini doesn't use "system" role in history content array generally for chat, usually config.systemInstruction
        // Flatten history for contents
        const contents = [
             ...contextHistory.map(h => ({ role: h.role === 'user' ? 'user' : 'model', parts: [{ text: h.content }] })),
             { role: 'user', parts: [{ text: userMsg }] }
        ];

        const result = await ai.models.generateContentStream({
            model: settings.model,
            contents: contents,
            config: {
                systemInstruction: fullSystemPrompt
            }
        });
        for await (const chunk of result) {
            fullOutput += chunk.text;
            yield { text: chunk.text };
        }
    } else {
         const res = await callOpenAI(
             settings.baseUrl || '', 
             settings.apiKey, 
             settings.model, 
             [
                 { role: 'system', content: fullSystemPrompt }, 
                 ...contextHistory, 
                 { role: 'user', content: userMsg }
             ]
         );
         fullOutput = res;
         yield { text: res };
    }
    
    // ğŸ†• è®°å½• Token ä½¿ç”¨
    tokenCounter.record(
        fullSystemPrompt + contextHistory.map(h => h.content).join('') + userMsg,
        fullOutput,
        settings.model,
        'chat'
    );
};

// --- Video / Audio ---

export const generateScenePrompts = async (text: string, settings: AppSettings): Promise<VideoScene[]> => {
    const prompt = `
        Convert the following text into 3-5 visual scenes for video generation.
        Text: ${text.slice(0, 3000)}
        
        Return JSON array: prompt (visual description, English, detailed), script (narration text).
    `;
    
    if (settings.provider === 'google') {
        const ai = getGoogleAI(settings);
        const res = await ai.models.generateContent({
            model: settings.model,
            contents: prompt,
            config: {
                responseMimeType: 'application/json',
                responseSchema: {
                    type: Type.ARRAY,
                    items: {
                        type: Type.OBJECT,
                        properties: {
                            prompt: { type: Type.STRING },
                            script: { type: Type.STRING }
                        }
                    }
                }
            }
        });
        const raw = JSON.parse(res.text || "[]");
        return raw.map((r: any) => ({
            id: crypto.randomUUID(),
            prompt: r.prompt,
            script: r.script,
            status: 'idle',
            timestamp: Date.now()
        }));
    }
    return [];
};

export const generateVideo = async (scene: VideoScene, settings: AppSettings, style: string): Promise<string | null> => {
    const ai = getGoogleAI(settings);
    
    // Veo 3.1
    let operation = await ai.models.generateVideos({
        model: settings.videoModel || 'veo-3.1-fast-generate-preview',
        prompt: `${style} Style. ${scene.prompt}`,
        config: {
            numberOfVideos: 1,
            aspectRatio: '16:9',
            resolution: '720p'
        }
    });
    
    // Poll for completion
    while (!operation.done) {
        await new Promise(resolve => setTimeout(resolve, 5000));
        operation = await ai.operations.getVideosOperation({ operation });
    }
    
    const uri = operation.response?.generatedVideos?.[0]?.video?.uri;
    if (uri) {
        const videoRes = await fetch(`${uri}&key=${settings.apiKey}`);
        if (!videoRes.ok) return null;
        const blob = await videoRes.blob();
        return URL.createObjectURL(blob);
    }
    return null;
};

export const generateSpeech = async (text: string, settings: AppSettings, voice: string): Promise<string | null> => {
    const ai = getGoogleAI(settings);
    const response = await ai.models.generateContent({
        model: settings.speechModel || 'gemini-2.5-flash-preview-tts',
        contents: { parts: [{ text }] },
        config: {
            responseModalities: [Modality.AUDIO],
            speechConfig: {
                voiceConfig: {
                    prebuiltVoiceConfig: { voiceName: voice || 'Kore' }
                }
            }
        }
    });
    
    const base64Audio = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
    if (base64Audio) {
        // Decode base64 to binary
        const binaryString = atob(base64Audio);
        const len = binaryString.length;
        const bytes = new Uint8Array(len);
        for (let i = 0; i < len; i++) {
            bytes[i] = binaryString.charCodeAt(i);
        }
        
        // Wrap in WAV container so standard HTML Audio element can play it
        return createWavUrl(bytes, 24000); 
    }
    return null;
};

// WAV Header generator for raw PCM data
function createWavUrl(samples: Uint8Array, sampleRate: number): string {
    const buffer = new ArrayBuffer(44 + samples.length);
    const view = new DataView(buffer);

    // RIFF chunk descriptor
    writeString(view, 0, 'RIFF');
    view.setUint32(4, 36 + samples.length, true);
    writeString(view, 8, 'WAVE');

    // fmt sub-chunk
    writeString(view, 12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true); // PCM
    view.setUint16(22, 1, true); // Mono
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * 2, true);
    view.setUint16(32, 2, true); // Block align
    view.setUint16(34, 16, true); // Bits per sample

    // data sub-chunk
    writeString(view, 36, 'data');
    view.setUint32(40, samples.length, true);

    // Write samples
    const offset = 44;
    for (let i = 0; i < samples.length; i++) {
        view.setUint8(offset + i, samples[i]);
    }

    const blob = new Blob([view], { type: 'audio/wav' });
    return URL.createObjectURL(blob);
}

function writeString(view: DataView, offset: number, string: string) {
    for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
    }
}
